///|
test "black-box test - using factory function and validation" {
  assert_eq(1 + 1, 2)
  assert_eq(2 + 2, 4)
  inspect([1, 2, 3], content="[1, 2, 3]")

  // ä½¿ç”¨å·¥å‚å‡½æ•°åˆ›å»º Location
  let l = @lexer.Location::new(from=0, to=1)
  // ä½¿ç”¨è®¿é—®å™¨æ–¹æ³•è·å–ä½ç½®ä¿¡æ¯
  assert_eq(@lexer.Location::from(l), 0)
  assert_eq(@lexer.Location::to(l), 1)
  // ä»ç„¶å¯ä»¥æ˜¾ç¤º Location
  inspect(Show::to_string(l), content="{from: 0, to: 1}")

  // æµ‹è¯•éªŒè¯é€»è¾‘
  inspect(
    try? @lexer.Location::new(from=2, to=1),
    content="Err(Failure(\"Invalid location: start position cannot be greater than end position\"))",
  )
}

///|
test "Lexer::new constructor" {
  let l = @lexer.Lexer::new(source="123")
  inspect(
    Show::to_string(l),
    content="{source: \"123\", tokens: @queue.of([]), err: None, current: {index: 0, bytes: 0}, eof: false}",
  )
}

///|
test "Token::new_empty constructor" {
  let empty_token = @lexer.Token::new_empty()
  inspect(
    Show::to_string(empty_token),
    content="{location: {from: 0, to: 0}, kind: EOF, value: \"\"}",
  )
}

///|
test "Lexer::next" {
  // Test normal character reading
  let lexer = Lexer::new(source="aÎ±ä¸­ğŸŒÃ©_â¤ï¸ ")
  inspect(lexer.next().unwrap(), content="a")
  inspect(lexer.current().pos(), content="1")
  inspect(lexer.current().index(), content="1")
  inspect(lexer.current().bytes(), content="1")
  inspect(lexer.eof(), content="false")

  inspect(lexer.next().unwrap(), content="Î±")
  inspect(lexer.current().pos(), content="2")
  inspect(lexer.current().index(), content="2")
  inspect(lexer.current().bytes(), content="3")
  inspect(lexer.eof(), content="false")

  inspect(lexer.next().unwrap(), content="ä¸­")
  inspect(lexer.current().pos(), content="3")
  inspect(lexer.current().index(), content="3")
  inspect(lexer.current().bytes(), content="6")
  inspect(lexer.eof(), content="false")

  inspect(lexer.next().unwrap(), content="ğŸŒ")
  inspect(lexer.current().pos(), content="4")
  inspect(lexer.current().index(), content="4")
  inspect(lexer.current().bytes(), content="10")
  inspect(lexer.eof(), content="false")

  inspect(lexer.next().unwrap(), content="Ã©")
  inspect(lexer.current().pos(), content="5")
  inspect(lexer.current().index(), content="6")
  inspect(lexer.current().bytes(), content="12")
  inspect(lexer.eof(), content="false")

  inspect(lexer.next().unwrap(), content="_")
  inspect(lexer.current().pos(), content="6")
  inspect(lexer.current().index(), content="7")
  inspect(lexer.current().bytes(), content="13")  
  inspect(lexer.eof(), content="false")

  // â€œâ¤ï¸â€æ˜¯ç”±ä¸¤ä¸ªç ç‚¹ç»„æˆçš„ç»„åˆå­—ç¬¦ï¼ˆâ¤ + ï¸ï¼‰ï¼ŒæŒ‰ç ç‚¹åˆ†åˆ«è¯»å–
  inspect(lexer.next().unwrap(), content="â¤")
  inspect(lexer.current().pos(), content="7")
  inspect(lexer.current().index(), content="8")
  inspect(lexer.current().bytes(), content="16")  
  inspect(lexer.eof(), content="false")
  ignore(lexer.next())
  //inspect(lexer.next().unwrap(), content=" ")
  inspect(lexer.current().pos(), content="8")
  inspect(lexer.current().index(), content="9")
  inspect(lexer.current().bytes(), content="19")  
  inspect(lexer.eof(), content="true")
}

///|
test "Lexer::next/eof" {
  // Test EOF behavior when reading beyond string length
  let lexer = Lexer::new(source=" ")
  inspect(lexer.next().unwrap(), content=" ")

  // Now reading beyond should set EOF and return null character
  inspect(lexer.next().is_empty(), content="true")
  inspect(lexer.eof(), content="true")
}

///|
test "Lexer::next/empty_source" {
  // Test behavior with empty source string
  let lexer = Lexer::new(source="")

  // First read should immediately set EOF and return null character
  inspect(lexer.next().is_empty(), content="true")
  inspect(lexer.eof(), content="true")
}

test "Lexer::backup" {
  // Test backup behavior
  let lexer = Lexer::new(source="ağŸŒÎ±â¤ï¸")
  ignore(lexer.next()) // Consume 'a'
  ignore(lexer.next()) // Consume 'ğŸŒ'
  ignore(lexer.next()) // Consume 'Î±'
  ignore(lexer.next()) // Consume 'â¤ï¸'
  lexer.backup()
  println(lexer.next().unwrap())
  // println(lexer.next().unwrap())
  lexer.backup()
  lexer.backup()
  // println(lexer.next().unwrap())
  lexer.backup()
  println(lexer.next().unwrap())
  // inspect(lexer.next().unwrap(), content="â¤ï¸")
  // lexer.backup()
  //  inspect(lexer.next().unwrap(), content="Î±")
  // lexer.backup()
  // inspect(lexer.next().unwrap(), content="ğŸŒ")
}


///|
test "Lexer::get_word" {
  let lexer = Lexer::new(source="ağŸŒÎ±â¤ï¸hello world ğŸ¤£ ")
  
 // ç§»åŠ¨åˆ° 'ğŸŒ' ä¹‹åï¼Œå¹¶è®¾ç½®åˆ‡ç‰‡èµ·ç‚¹
  ignore(lexer.next()) // 'a'
  ignore(lexer.next()) // 'ğŸŒ'
  inspect(lexer.get_word(), content="ağŸŒ")
  lexer.commit()

  // è¯»å– 'Î±'ï¼Œæ­¤æ—¶åˆ‡ç‰‡åº”ä¸º "Î±"
  ignore(lexer.next()) // 'Î±'
  let t1 = lexer.get_word()
  inspect(t1, content="Î±")

  // è¯»å–â€œâ¤ï¸â€çš„ç¬¬ä¸€ä¸ªç ç‚¹ 'â¤'ï¼Œåˆ‡ç‰‡è§†å›¾åº”æ‰©å±•ä¸º "Î±â¤"
  ignore(lexer.next()) // 'â¤'
  ignore(lexer.next())
  let t2 = lexer.get_word()
  inspect(t2, content="Î±â¤ï¸")

  // è¯»å– "hello " å¹¶æ–­è¨€
  lexer.commit()
  ignore(lexer.next()) // 'h'
  ignore(lexer.next()) // 'e'
  ignore(lexer.next()) // 'l'
  ignore(lexer.next()) // 'l'
  ignore(lexer.next()) // 'o'
  println(lexer.get_word())
  inspect(lexer.get_word(), content="hello")

  // è¯»å– "world ğŸ¤£ " å¹¶æ–­è¨€
  lexer.commit()
  ignore(lexer.next()) // 'w'
  ignore(lexer.next()) // 'o'
  ignore(lexer.next()) // 'r'
  ignore(lexer.next()) // 'l'
  ignore(lexer.next()) // 'd'
  ignore(lexer.next()) // ' '
  ignore(lexer.next()) // 'ğŸ¤£'
  ignore(lexer.next()) // ' '
  ignore(lexer.next()) // ' '
  println(lexer.current())
  inspect(lexer.get_word(), content=" world ğŸ¤£ ")
  println("ağŸŒÎ±â¤ï¸hello world ğŸ¤£A"[:][11:21])
}

test "String test"{
  let s = "ağŸŒÎ±â¤ï¸hello world ğŸ¤£ "[:]
  println(s[1:3])
  println(s[4:6])
  println(s[6:7])
}